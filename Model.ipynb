{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5290efaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0480d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "df = pd.read_csv(\"/Users/shubanborkar/Documents/GitHub/Carbon-Footprint-Prediction/emissions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26477932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced Feature Engineering\n",
    "categorical_features = ['CompanyID', 'CompanyName', 'Sector', 'Location', 'Year']\n",
    "numerical_features = ['CH4', 'N2O', 'Electricity', 'FossilFuels', 'Renewables', \n",
    "                     'RecycledWaste', 'LandfillWaste', 'CompostedWaste']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b9376a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical encoding\n",
    "for feat in categorical_features:\n",
    "    df[f'{feat}_encoded'] = df[feat].astype('category').cat.codes.astype(np.float32)  # Ensure float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b122f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create interaction features\n",
    "df['Energy_Mix'] = (df['Electricity'] / (df['FossilFuels'] + df['Renewables'] + 1e-8)).astype(np.float32)\n",
    "df['Waste_Ratio'] = (df['RecycledWaste'] / (df['LandfillWaste'] + df['CompostedWaste'] + 1e-8)).astype(np.float32)\n",
    "df['GHG_Intensity'] = ((df['CH4'] * 25 + df['N2O'] * 298) / (df['CO2'] + 1e-8)).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca105cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select Features & Target\n",
    "features = ([f'{feat}_encoded' for feat in categorical_features] + \n",
    "           numerical_features + ['Energy_Mix', 'Waste_Ratio', 'GHG_Intensity'])\n",
    "target = 'CO2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e86608d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Convert to numpy arrays with explicit dtype\n",
    "X = df[features].values.astype(np.float32)\n",
    "y = df[target].values.astype(np.float32).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b422a992",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Robust Normalization\n",
    "def robust_normalize(data):\n",
    "    mean = np.mean(data, axis=0)\n",
    "    std = np.std(data, axis=0) + 1e-8\n",
    "    return (data - mean) / std, mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92aaaeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_normalized, X_mean, X_std = robust_normalize(X)\n",
    "y_normalized, y_mean, y_std = robust_normalize(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e73ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Validation-Test Split\n",
    "np.random.seed(42)\n",
    "indices = np.random.permutation(len(X))\n",
    "train_size = int(0.7 * len(X))\n",
    "val_size = int(0.15 * len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c3e106",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx = indices[:train_size]\n",
    "val_idx = indices[train_size:train_size + val_size]\n",
    "test_idx = indices[train_size + val_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66b1dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = X_normalized[train_idx], y_normalized[train_idx]\n",
    "X_val, y_val = X_normalized[val_idx], y_normalized[val_idx]\n",
    "X_test, y_test = X_normalized[test_idx], y_normalized[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5acc749",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Convert to PyTorch tensors with explicit dtype\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c6dc7a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class EmissionsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3e94b3",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# DataLoaders\n",
    "batch_size = min(32, len(X_train) // 10)\n",
    "train_loader = torch.utils.data.DataLoader(EmissionsDataset(X_train_tensor, y_train_tensor), \n",
    "                                         batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(EmissionsDataset(X_val_tensor, y_val_tensor), \n",
    "                                       batch_size=batch_size, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(EmissionsDataset(X_test_tensor, y_test_tensor), \n",
    "                                        batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed73d9f",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class CO2Predictor(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_size, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            \n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "        \n",
    "        # Initialize weights\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "                \n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf4a3ad",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Initialize model and training components\n",
    "model = CO2Predictor(X_train.shape[1])\n",
    "criterion = nn.HuberLoss(delta=1.0)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, \n",
    "                                               patience=5, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f5cd0d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X_batch)\n",
    "        loss = criterion(output, y_batch)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016e510a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def validate(model, val_loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            output = model(X_batch)\n",
    "            loss = criterion(output, y_batch)\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd62cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training with early stopping\n",
    "num_epochs = 200\n",
    "patience = 15\n",
    "min_delta = 1e-4\n",
    "best_val_loss = float('inf')\n",
    "counter = 0\n",
    "best_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73cafef",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    train_loss = train_epoch(model, train_loader, criterion, optimizer)\n",
    "    val_loss = validate(model, val_loader, criterion)\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "    \n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    if val_loss < best_val_loss - min_delta:\n",
    "        best_val_loss = val_loss\n",
    "        best_epoch = epoch\n",
    "        torch.save(model.state_dict(), \"co2_emission_best.pt\")\n",
    "        counter = 0\n",
    "    else:\n",
    "        counter += 1\n",
    "        if counter >= patience:\n",
    "            print(f\"Early stopping triggered. Best epoch was {best_epoch + 1}\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfd14db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Model\n",
    "model.load_state_dict(torch.load(\"co2_emission_best.pt\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cab9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    test_predictions = model(X_test_tensor).numpy()\n",
    "    \n",
    "    # Denormalize predictions and actual values\n",
    "    test_predictions = test_predictions * y_std + y_mean\n",
    "    actual_values = y_test * y_std + y_mean\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mse = np.mean((actual_values - test_predictions) ** 2)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = np.mean(np.abs(actual_values - test_predictions))\n",
    "    r2 = 1 - (np.sum((actual_values - test_predictions) ** 2) / \n",
    "              np.sum((actual_values - np.mean(actual_values)) ** 2))\n",
    "    \n",
    "    print(\"\\nModel Performance:\")\n",
    "    print(f\"R² Score: {r2:.4f}\")\n",
    "    print(f\"RMSE: {rmse:.2f}\")\n",
    "    print(f\"MAE: {mae:.2f}\")\n",
    "    print(f\"\\nSample Predictions:\")\n",
    "    for i in range(min(5, len(test_predictions))):\n",
    "        print(f\"Actual: {actual_values[i][0]:.2f}, Predicted: {test_predictions[i][0]:.2f}, \"\n",
    "              f\"Error: {abs(actual_values[i][0] - test_predictions[i][0]):.2f}\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
